{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook formats the CLAMP output (i.e. predictions) for the PubMed abstracts and full-texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configurations that can be modified\n",
    "ABSTRACT = False # True if running this program of abstracts, False if running on full-texts\n",
    "CLAMP_DIRECTORY = \"clamp\" # parent directory for CLAMP-related files\n",
    "\n",
    "# location of full-texts/abstracts in plain text\n",
    "INPUT_DIRECTORY_FULL_TEXT = \"pubmed_fulltexts_544\"\n",
    "INPUT_DIRECTORY_ABSTRACT = \"pubmed_abstracts_20408\"\n",
    "\n",
    "# CLAMP output/predictions\n",
    "CLAMP_OUTPUT_DIRECTORY_FULL_TEXT = os.path.join(CLAMP_DIRECTORY, \"clamp_output_full_text\") \n",
    "CLAMP_OUTPUT_DIRECTORY_ABSTRACT = os.path.join(CLAMP_DIRECTORY, \"clamp_output_abstract\") \n",
    "\n",
    "# formatted CLAMP output/predictions\n",
    "CLAMP_RESULTS_DIRECTORY_FULL_TEXT = os.path.join(CLAMP_DIRECTORY, \"clamp_results_full_text\")\n",
    "CLAMP_RESULTS_DIRECTORY_ABSTRACT = os.path.join(CLAMP_DIRECTORY, \"clamp_results_abstract\")\n",
    "\n",
    "if ABSTRACT:\n",
    "    CLAMP_OUTPUT_DIRECTORY = CLAMP_OUTPUT_DIRECTORY_ABSTRACT\n",
    "    CLAMP_RESULTS_DIRECTORY = CLAMP_RESULTS_DIRECTORY_ABSTRACT \n",
    "    INPUT_DIRECTORY = INPUT_DIRECTORY_ABSTRACT\n",
    "else:\n",
    "    CLAMP_OUTPUT_DIRECTORY = CLAMP_OUTPUT_DIRECTORY_FULL_TEXT\n",
    "    CLAMP_RESULTS_DIRECTORY = CLAMP_RESULTS_DIRECTORY_FULL_TEXT\n",
    "    INPUT_DIRECTORY = INPUT_DIRECTORY_FULL_TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def extract_entity(full_text, row):\n",
    "    ent = full_text[row['Start']:row['End']]\n",
    "    return ent\n",
    "\n",
    "def extract_sentence(sentences, row):\n",
    "    ent_start = row['Start']\n",
    "    for s in sentences:\n",
    "        if s.start_char <= ent_start and ent_start < s.end_char:\n",
    "            return s.text\n",
    "    return \"\"\n",
    "\n",
    "def is_file_empty(DIRECTORY, filename):\n",
    "    with open(os.path.join(DIRECTORY, filename)) as f:\n",
    "        data = f.read()\n",
    "        \n",
    "    return data.isspace() or data == \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 PMC5419910.txt\n",
      "5 PMC5331586.txt\n",
      "10 PMC4359103.txt\n",
      "15 PMC6479357.txt\n",
      "20 PMC6096788.txt\n",
      "25 PMC6450841.txt\n",
      "30 PMC5948870.txt\n",
      "35 PMC6706698.txt\n",
      "40 PMC5789214.txt\n",
      "45 PMC3641085.txt\n",
      "50 PMC5432605.txt\n",
      "55 PMC4946778.txt\n",
      "60 PMC5352792.txt\n",
      "65 PMC6696098.txt\n",
      "70 PMC5627471.txt\n",
      "75 PMC6361977.txt\n",
      "80 PMC4619728.txt\n",
      "85 PMC6414208.txt\n",
      "90 PMC5609014.txt\n",
      "95 PMC5481972.txt\n",
      "100 PMC6218441.txt\n",
      "105 PMC5775320.txt\n",
      "110 PMC6282609.txt\n",
      "115 PMC6133091.txt\n",
      "120 PMC5360849.txt\n",
      "125 PMC6199253.txt\n",
      "130 PMC5889781.txt\n",
      "135 PMC6521002.txt\n",
      "140 PMC6136574.txt\n",
      "145 PMC5416705.txt\n",
      "150 PMC6025870.txt\n",
      "155 PMC4534101.txt\n",
      "160 PMC3827355.txt\n",
      "165 PMC2903486.txt\n",
      "170 PMC6450836.txt\n",
      "175 PMC6417160.txt\n",
      "180 PMC5681818.txt\n",
      "185 PMC6061016.txt\n",
      "190 PMC5680520.txt\n",
      "195 PMC6045598.txt\n",
      "200 PMC2663032.txt\n",
      "205 PMC5304941.txt\n",
      "210 PMC6628259.txt\n",
      "215 PMC3501481.txt\n",
      "220 PMC5192959.txt\n",
      "225 PMC6373295.txt\n",
      "230 PMC2731203.txt\n",
      "235 PMC6389139.txt\n",
      "240 PMC2582449.txt\n",
      "245 PMC6546658.txt\n",
      "250 PMC5700871.txt\n",
      "255 PMC6082980.txt\n",
      "260 PMC4638355.txt\n",
      "265 PMC6466354.txt\n",
      "270 PMC6595579.txt\n",
      "275 PMC6044100.txt\n",
      "280 PMC6394789.txt\n",
      "285 PMC5486135.txt\n",
      "290 PMC6105175.txt\n",
      "295 PMC6263710.txt\n",
      "300 PMC5751211.txt\n",
      "305 PMC6143081.txt\n",
      "310 PMC6509633.txt\n",
      "315 PMC5116076.txt\n",
      "320 PMC5683395.txt\n",
      "325 PMC5570931.txt\n",
      "330 PMC4511760.txt\n",
      "335 PMC6120494.txt\n",
      "340 PMC5487761.txt\n",
      "345 PMC3182210.txt\n",
      "350 PMC6153902.txt\n",
      "355 PMC6408059.txt\n",
      "360 PMC6772177.txt\n",
      "365 PMC6245048.txt\n",
      "370 PMC3382122.txt\n",
      "375 PMC6708801.txt\n",
      "380 PMC3584132.txt\n",
      "385 PMC6667418.txt\n",
      "390 PMC6133004.txt\n",
      "395 PMC6107940.txt\n",
      "400 PMC3183050.txt\n",
      "405 PMC5569583.txt\n",
      "410 PMC6349414.txt\n",
      "415 PMC6539237.txt\n",
      "420 PMC5360850.txt\n",
      "425 PMC4789644.txt\n",
      "430 PMC5509841.txt\n",
      "435 PMC5563911.txt\n",
      "440 PMC6341088.txt\n",
      "445 PMC6022232.txt\n",
      "450 PMC5584030.txt\n",
      "455 PMC5791309.txt\n",
      "460 PMC6483965.txt\n",
      "465 PMC5225659.txt\n",
      "470 PMC5485071.txt\n",
      "475 PMC5328751.txt\n",
      "480 PMC5623420.txt\n",
      "485 PMC5317002.txt\n",
      "490 PMC5571902.txt\n",
      "495 PMC6813284.txt\n",
      "500 PMC6287949.txt\n",
      "505 PMC5545734.txt\n",
      "510 PMC5832686.txt\n",
      "515 PMC5642793.txt\n",
      "520 PMC6258483.txt\n",
      "525 PMC6129765.txt\n",
      "530 PMC5574313.txt\n",
      "535 PMC6471505.txt\n",
      "540 PMC5536256.txt\n"
     ]
    }
   ],
   "source": [
    "# format CLAMP output/predictions in csv format where one row is one NER prediction\n",
    "empty_input_files = []\n",
    "with open(os.path.join(CLAMP_RESULTS_DIRECTORY, \"clamp_preds.csv\"), \"w\") as csv_file:\n",
    "    csv_writer = csv.writer(csv_file, delimiter=',', quoting=csv.QUOTE_MINIMAL)\n",
    "    header = ['Start', 'End', 'Semantic', 'CUI', 'Assertion', 'Entity', 'paper',\n",
    "       'Entity_matched', 'Sentence_pred']\n",
    "    csv_writer.writerow(header)\n",
    "    \n",
    "    clamp_files = [filename for filename in os.listdir(CLAMP_OUTPUT_DIRECTORY) if filename.endswith(\".txt\")]\n",
    "    for idx, filename in enumerate(clamp_files):\n",
    "\n",
    "        if ABSTRACT and idx % 1000 == 0:\n",
    "            print(idx, filename)\n",
    "        elif not ABSTRACT and idx % 5 == 0:\n",
    "            print(idx, filename)\n",
    "            \n",
    "        if is_file_empty(INPUT_DIRECTORY, filename):\n",
    "            empty_input_files.append(filename)\n",
    "            continue\n",
    "            \n",
    "        # ignore empty files\n",
    "        if is_file_empty(CLAMP_OUTPUT_DIRECTORY, filename):\n",
    "            continue\n",
    "\n",
    "        with open(os.path.join(INPUT_DIRECTORY, filename)) as f:\n",
    "            full_text = f.read()\n",
    "            doc = nlp(full_text)\n",
    "\n",
    "        df = pd.read_csv(os.path.join(CLAMP_OUTPUT_DIRECTORY, filename), sep=\"\\t\", quoting=3)\n",
    "        df[\"paper\"] = filename\n",
    "        df[\"Entity_matched\"] = list(df.apply(lambda row: extract_entity(full_text, row), axis=1))\n",
    "        df[\"Sentence_pred\"] = df.apply(lambda row: extract_sentence(doc.sents, row), axis=1)\n",
    "\n",
    "        for i, row in df.iterrows():\n",
    "            csv_writer.writerow(list(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of empty input files 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of empty input files\", len(empty_input_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty_input_files"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
